{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..'))) # access sibling directories\n",
    "\n",
    "from src.python.models import MainSimulator\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng() # Use 2022 for stable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal-detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mu_h &\\sim \\mathcal{N}(0, 1) \\\\\n",
    "\\sigma_h &\\sim \\textrm{Gamma}(1, 1)\\\\\n",
    "\\mu_f &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "\\sigma_f &\\sim \\textrm{Gamma}(1, 1)\\\\\n",
    "h_m &\\sim \\mathcal{N}(\\mu_h, \\sigma_h) \\text{ for } m=1,\\dots,M\\\\\n",
    "f_m &\\sim \\mathcal{N}(\\mu_f, \\sigma_f) \\text{ for } m=1,\\dots,M\\\\\n",
    "x_n^{h}|h_m &\\sim \\textrm{Bin}(O_m, \\Phi(h_m)) \\text{ for } n=1,\\dots,N_m\\\\\n",
    "x_n^{f}|f_m &\\sim \\textrm{Bin}(W_m, \\Phi(f_m)) \\text{ for } n=1,\\dots,N_m\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi =$ Standard normal cumulative distribution function\n",
    "\n",
    "$h_m = \\Phi^{-1}(p_m^{(h)}) =$ probit-transformed hit probability (on old items)\n",
    "\n",
    "$f_m = \\Phi^{-1}(p_m^{(f)}) =$ probit-transformed false alarm probability (on new items)\n",
    "\n",
    "$O_m =$ Number of old/signal trials per participant m\n",
    "\n",
    "$W_m =$ Number of new/noise trials per participant m\n",
    "\n",
    "[Notation follows Rouder & Lu (2005)]\n",
    "\n",
    "[Priors are informed by the results of Greene, Martin & Naveh-Benjamin (2021)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We code stimulus type and response as\n",
    "- 0 = \"new\"\n",
    "- 1 = \"old\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPT model (2HTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "d_m &\\sim \\text{ for } m=1,\\dots,M\\\\\n",
    "g_m &\\sim \\text{ for } m=1,\\dots,M\\\\\n",
    "p_m(\\textrm{hit}|\\textrm{old}) &\\sim d_m + (1-d_m)*g_m \\text{ for } m=1,\\dots,M\\\\\n",
    "p_m(\\textrm{false alarm}|\\textrm{new}) &\\sim (1-d_m)*g_m \\text{ for } m=1,\\dots,M\\\\\n",
    "x_n^{\\textrm{old}} &\\sim \\textrm{Bin}(1, p_m(\\textrm{hit}|\\textrm{old})) \\text{ for } n=1,\\dots,N_m\\\\\n",
    "x_n^{\\textrm{new}} &\\sim \\textrm{Bin}(1, p_m(\\textrm{false alarm}|\\textrm{new})) \\text{ for } n=1,\\dots,N_m\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired data structure: (x, M, N, 2) \n",
    "- x data sets\n",
    "- M participants\n",
    "- N trials per participant\n",
    "- 2 Variables (stimulus_type, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers:\n",
    "# Find percentage of a value with stats.norm.cdf()\n",
    "# Find value leading to a specific percentage with stats.norm.ppf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 100\n",
    "n_obs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw from prior\n",
    "# TODO: Clarify if using Variance notation or SD notation!!!\n",
    "\n",
    "class HierarchicalSdtMptSimulator:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def draw_from_prior(self, model_index, n_clusters):\n",
    "        \"\"\" Draws parameter values from the specified prior distributions of the hyperprior and the conditional prior.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_index : int\n",
    "            Index of the model to be simulated from.\n",
    "        n_clusters : int\n",
    "            Number of higher order clusters that the observations are nested in.\n",
    "        \"\"\"\n",
    "\n",
    "        if model_index == 0: # SDT model\n",
    "\n",
    "            # Hyperpriors\n",
    "            mu_h = RNG.normal(0.5, 1)\n",
    "            sigma_h = RNG.gamma(1, 1)\n",
    "            mu_f = RNG.normal(-1, 1)\n",
    "            sigma_f = RNG.gamma(1, 1)\n",
    "\n",
    "            # Group-level priors\n",
    "            h_m = RNG.normal(loc=mu_h, scale=sigma_h, size=n_clusters)\n",
    "            f_m = RNG.normal(loc=mu_f, scale=sigma_f, size=n_clusters)\n",
    "\n",
    "        if model_index == 1: # MPT model\n",
    "            # TODO\n",
    "            h_m = 1 # TEMPORARY\n",
    "            f_m = 1 # TEMPORARY\n",
    "        \n",
    "        return h_m, f_m\n",
    "\n",
    "    def generate_from_likelihood(self, h_m, f_m, n_clusters, n_obs):\n",
    "        \"\"\" Generates a single hierarchical data set from the sampled parameter values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h_m : np.array\n",
    "            Probit-transformed hit probability.\n",
    "        f_m : np.array\n",
    "            Probit-transformed false alarm probability.\n",
    "        n_clusters : int\n",
    "            Number of higher order clusters that the observations are nested in.\n",
    "        n_obs : int\n",
    "            Number of observations per cluster.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : np.array\n",
    "            Generated data set with shape (n_clusters, n_obs, 2).\n",
    "            Contains 2 binary variables with stimulus type and response (for both applies: 0=\"new\" / 1=\"old\").\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine amount of signal (old item) and noise (new item) trials\n",
    "        assert n_obs%2 == 0, \"n_obs has to be dividable by 2.\"\n",
    "        n_trials_per_cat = int(n_obs/2)\n",
    "\n",
    "        # Create stimulus types (0=\"new\" / 1=\"old\")\n",
    "        stim_cluster = np.repeat([[1,0]], repeats=n_trials_per_cat, axis=1) # for 1 participant\n",
    "        stim_data_set = np.repeat(stim_cluster, repeats=n_clusters, axis=0) # for 1 data set\n",
    "\n",
    "        # Create individual responses (0=\"new\" / 1=\"old\")\n",
    "        X_h = RNG.binomial(n=1, p=stats.norm.cdf(h_m), size=(n_trials_per_cat, n_clusters)).T # Old items\n",
    "        X_f = RNG.binomial(n=1, p=stats.norm.cdf(f_m), size=(n_trials_per_cat, n_clusters)).T # New items\n",
    "        X_responses = np.concatenate((X_h, X_f), axis=1)\n",
    "\n",
    "        # Create final data set\n",
    "        X = np.stack((stim_data_set, X_responses), axis=2)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def generate_single(self, model_index, n_clusters, n_obs):\n",
    "        \"\"\"Generates a single hierarchical data set utilizing the draw_from_prior and gen_from_likelihood functions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_index : int\n",
    "            Index of the model to be simulated from.\n",
    "        n_clusters : int\n",
    "            Number of higher order clusters that the observations are nested in.\n",
    "        n_obs : int\n",
    "            Number of observations per cluster.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : np.array\n",
    "            Generated data set with shape (n_clusters, n_obs, 2).\n",
    "            Contains 2 binary variables with stimulus type and response (for both applies: 0=\"new\" / 1=\"old\").\n",
    "        \"\"\"\n",
    "\n",
    "        h_m, f_m = self.draw_from_prior(model_index, n_clusters)\n",
    "        X = self.generate_from_likelihood(h_m, f_m, n_clusters, n_obs)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        ...,\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test class on one data set\n",
    "simulator_single = HierarchicalSdtMptSimulator()\n",
    "simulator_single.generate_single(0, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " None,\n",
       " array([[[[1., 1.],\n",
       "          [1., 0.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 0.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[1., 1.],\n",
       "          [1., 0.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]]],\n",
       " \n",
       " \n",
       "        [[[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 0.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 0.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]]],\n",
       " \n",
       " \n",
       "        [[[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]]]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test class on multiple data sets\n",
    "def n_clust_obs():\n",
    "    \"\"\"\n",
    "    Nasty hack to make compatible with BayesFlow.\n",
    "    Defines a fixed number of clusters and observations.\n",
    "    \"\"\"\n",
    "    \n",
    "    M = 50\n",
    "    N = 50\n",
    "    return (M, N)\n",
    "\n",
    "simulator = MainSimulator(HierarchicalSdtMptSimulator())\n",
    "simulator(5, (100,50), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior predictive checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit prob and false alarm prob for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit rates and false alarm rates for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample Params from hyperpriors then transform to [0,1] space applying stats.cdf()\n",
    "# probit transformation = applying cumulative normal dist? -> same for SDT!!\n",
    "# See Klauer (2010)\n",
    "\n",
    "# probability = cumulative normal (param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-hierarchical modeling of single responses\n",
    "d = 0.7 # TreeBUGS default\n",
    "g = 0.5 # TreeBUGS default\n",
    "size = 10\n",
    "\n",
    "hits = RNG.binomial(n=1, p=(d + (1-d)*g), size=size) # p(hit|old) = d + (1-d)*g\n",
    "false_alarms = RNG.binomial(n=1, p=((1-d)*g), size=size)# p(FA|new) = (1-d)*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 0] 0.9\n",
      "[0 0 0 0 0 1 0 0 0 0] 0.1\n"
     ]
    }
   ],
   "source": [
    "print(hits, np.mean(hits))\n",
    "print(false_alarms, np.mean(false_alarms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27a86c9f63fe2f1aa7d9f3c637434a8367b5c148236c1390e91d25c0e560ef1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
